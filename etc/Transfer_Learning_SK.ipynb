{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "-U2PfzQbqjq_",
        "F5kl1vfP7mjx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suinkangme/comp433_project/blob/main/Transfer_Learning_SK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Developing a robust CNN model to address the challenge of learning with label noise in  CIFAR10 dataset\n",
        "\n",
        "- CIFAR10 Label : ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
        "\n",
        "- image size : 3x32x32\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TyD3ZYpdMfXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "from torchvision.models import resnet18"
      ],
      "metadata": {
        "id": "ItN3Ur88Mbn1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and normalize CIFAR10\n",
        "\n",
        "- Transform them to Tensors of normalized range [-1, 1]."
      ],
      "metadata": {
        "id": "Mby_AXQNk9k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "cifar10_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)"
      ],
      "metadata": {
        "id": "em4BZ8EAmHGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5fc5ec9-ccc3-4446-a4b2-29d1d184d8b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation, test dataset\n",
        "test_val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])"
      ],
      "metadata": {
        "id": "CwdaaOWA5fSa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into train and validation\n",
        "train_size = int(0.8 * len(cifar10_dataset))\n",
        "val_size = len(cifar10_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(cifar10_dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "laHDmghE6YLN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.dataset.transform = train_transform\n",
        "val_dataset.dataset.transform = test_val_transform\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "4HUffu9C6q3T"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_val_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rekxxb1b6YQM",
        "outputId": "eab66591-2097-4369-c008-224a62ed1f2a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Noise Labeling\n",
        "- 5 different noise levels (10%,\n",
        "30%, 50%, 80%, 90%)"
      ],
      "metadata": {
        "id": "-U2PfzQbqjq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_label_noise(labels, epsilon, noise_type):\n",
        "    num_labels = len(labels)\n",
        "    num_flips = int(epsilon * num_labels)\n",
        "\n",
        "    if noise_type == 'symmetric':\n",
        "        # Symmetric label noise\n",
        "        flip_indices = np.random.choice(num_labels, num_flips, replace=False)\n",
        "        labels[flip_indices] = np.random.randint(0, 10, num_flips)\n",
        "    elif noise_type == 'asymmetric':\n",
        "        # Asymmetric label noise\n",
        "        flip_rules = {\n",
        "            9: 1,   # Truck to Automobile\n",
        "            2: 0,   # Bird to Airplane\n",
        "            4: 7,   # Deer to Horse\n",
        "            3: 5,   # Cat to Dog\n",
        "            5: 3,   # Dog to Cat\n",
        "        }\n",
        "\n",
        "        for i in range(num_labels):\n",
        "            if np.random.random() < epsilon:\n",
        "                labels[i] = flip_rules.get(labels[i], labels[i])\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "tyxVnHB5k2a5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Baseline Model**"
      ],
      "metadata": {
        "id": "qrSJVpxjNj2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a  baseline CNN model"
      ],
      "metadata": {
        "id": "cqkWDzlPmd8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaselineModel, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # fc layers\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(128 * 8 * 8, 120),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(84, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kGhXTfeRmeLA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train & Validation and Testing - symmetric noise label"
      ],
      "metadata": {
        "id": "F5kl1vfP7mjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# noise_levels\n",
        "noise_levels = [0.1, 0.3, 0.5, 0.8, 0.9]\n",
        "\n",
        "# create a dictionary with keys in the format 'noise_level_{100 * value}'\n",
        "model_dict = {f'noise_level_{int(100 * level)}_sy': None for level in noise_levels}\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# training\n",
        "for epsilon in noise_levels:\n",
        "\n",
        "    num_epochs = 5\n",
        "\n",
        "    model = BaselineModel()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    print(f\"Symmetric Training with noise level: {epsilon}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            # add symmetric noise to labels\n",
        "            labels = apply_label_noise(labels.numpy(), epsilon=epsilon, noise_type='symmetric')\n",
        "            labels = torch.from_numpy(labels)\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    average_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f'Validation Loss: {average_val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "    # save model to dictionary\n",
        "    model_dict[f'noise_level_{int(100 * epsilon)}_sy'] = {\n",
        "        'state_dict': model.state_dict(),\n",
        "        'validation_loss': average_val_loss,\n",
        "        'validation_accuracy': val_accuracy\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lna2HUsA7JS5",
        "outputId": "06b3e829-3804-4f4d-acf2-0e69b63af5ce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symmetric Training with noise level: 0.1\n",
            "Epoch 1/5, Loss: 1.574057936668396\n",
            "Epoch 2/5, Loss: 1.313593864440918\n",
            "Epoch 3/5, Loss: 1.4688284397125244\n",
            "Epoch 4/5, Loss: 0.9660269021987915\n",
            "Epoch 5/5, Loss: 1.2292925119400024\n",
            "Validation Loss: 0.9072915968621612, Validation Accuracy: 0.6976\n",
            "Symmetric Training with noise level: 0.3\n",
            "Epoch 1/5, Loss: 1.8488606214523315\n",
            "Epoch 2/5, Loss: 1.9562700986862183\n",
            "Epoch 3/5, Loss: 1.7214739322662354\n",
            "Epoch 4/5, Loss: 1.7651171684265137\n",
            "Epoch 5/5, Loss: 1.7388719320297241\n",
            "Validation Loss: 1.1064094020302888, Validation Accuracy: 0.6697\n",
            "Symmetric Training with noise level: 0.5\n",
            "Epoch 1/5, Loss: 2.238291025161743\n",
            "Epoch 2/5, Loss: 2.085500955581665\n",
            "Epoch 3/5, Loss: 1.895177960395813\n",
            "Epoch 4/5, Loss: 1.9388082027435303\n",
            "Epoch 5/5, Loss: 2.0612411499023438\n",
            "Validation Loss: 1.4341619804406622, Validation Accuracy: 0.6197\n",
            "Symmetric Training with noise level: 0.8\n",
            "Epoch 1/5, Loss: 2.3039259910583496\n",
            "Epoch 2/5, Loss: 2.3062257766723633\n",
            "Epoch 3/5, Loss: 2.2811570167541504\n",
            "Epoch 4/5, Loss: 2.2697012424468994\n",
            "Epoch 5/5, Loss: 2.3098952770233154\n",
            "Validation Loss: 2.1514614266195116, Validation Accuracy: 0.3304\n",
            "Symmetric Training with noise level: 0.9\n",
            "Epoch 1/5, Loss: 2.3032612800598145\n",
            "Epoch 2/5, Loss: 2.300058126449585\n",
            "Epoch 3/5, Loss: 2.301175832748413\n",
            "Epoch 4/5, Loss: 2.3037028312683105\n",
            "Epoch 5/5, Loss: 2.3018391132354736\n",
            "Validation Loss: 2.3027661013755067, Validation Accuracy: 0.1021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "for key, model_state_info in model_dict.items():\n",
        "\n",
        "    model = BaselineModel()\n",
        "    model_state = model.state_dict()\n",
        "    model_state.update({k: v for k, v in model_state_info['state_dict'].items() if k in model_state})\n",
        "\n",
        "    # load the updated state_dict\n",
        "    model.load_state_dict(model_state)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy for {key}: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7Uv61au89vx",
        "outputId": "40d0c8b9-61c3-4e0d-e09a-50845709dd94"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for noise_level_10_sy: 0.6976\n",
            "Test Accuracy for noise_level_30_sy: 0.6697\n",
            "Test Accuracy for noise_level_50_sy: 0.6197\n",
            "Test Accuracy for noise_level_80_sy: 0.3304\n",
            "Test Accuracy for noise_level_90_sy: 0.1021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train & Validation and Testing - asymmetric noise label"
      ],
      "metadata": {
        "id": "MP5bB-Jn716l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# noise_levels\n",
        "noise_levels = [0.1, 0.3, 0.5, 0.8, 0.9]\n",
        "\n",
        "# create a dictionary with keys in the format 'noise_level_{100 * value}'\n",
        "model_dict = {f'noise_level_{int(100 * level)}_asy': None for level in noise_levels}\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# training\n",
        "for epsilon in noise_levels:\n",
        "\n",
        "    num_epochs = 5\n",
        "\n",
        "    model = BaselineModel()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    print(f\"Asymmetric Training with noise level: {epsilon}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            # add symmetric noise to labels\n",
        "            labels = apply_label_noise(labels.numpy(), epsilon=epsilon, noise_type='asymmetric')\n",
        "            labels = torch.from_numpy(labels)\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    average_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f'Validation Loss: {average_val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "    # save model to dictionary\n",
        "    model_dict[f'noise_level_{int(100 * epsilon)}_asy'] = {\n",
        "        'state_dict': model.state_dict(),\n",
        "        'validation_loss': average_val_loss,\n",
        "        'validation_accuracy': val_accuracy\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_nb_gK97boB",
        "outputId": "7a424651-02a5-49ce-a6f5-ef654ab0a4f1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asymmetric Training with noise level: 0.1\n",
            "Epoch 1/5, Loss: 1.2843244075775146\n",
            "Epoch 2/5, Loss: 1.099171757698059\n",
            "Epoch 3/5, Loss: 1.091235637664795\n",
            "Epoch 4/5, Loss: 0.7557635307312012\n",
            "Epoch 5/5, Loss: 0.8707022666931152\n",
            "Validation Loss: 0.8434161699501572, Validation Accuracy: 0.7085\n",
            "Asymmetric Training with noise level: 0.3\n",
            "Epoch 1/5, Loss: 1.4024876356124878\n",
            "Epoch 2/5, Loss: 1.2790480852127075\n",
            "Epoch 3/5, Loss: 1.1926416158676147\n",
            "Epoch 4/5, Loss: 0.9048477411270142\n",
            "Epoch 5/5, Loss: 0.8954256772994995\n",
            "Validation Loss: 0.9617564602262655, Validation Accuracy: 0.679\n",
            "Asymmetric Training with noise level: 0.5\n",
            "Epoch 1/5, Loss: 1.2890602350234985\n",
            "Epoch 2/5, Loss: 1.0025088787078857\n",
            "Epoch 3/5, Loss: 0.9534822702407837\n",
            "Epoch 4/5, Loss: 0.8951865434646606\n",
            "Epoch 5/5, Loss: 1.0448288917541504\n",
            "Validation Loss: 1.0258914528379015, Validation Accuracy: 0.5956\n",
            "Asymmetric Training with noise level: 0.8\n",
            "Epoch 1/5, Loss: 1.4586886167526245\n",
            "Epoch 2/5, Loss: 1.0877671241760254\n",
            "Epoch 3/5, Loss: 1.2588895559310913\n",
            "Epoch 4/5, Loss: 0.782691240310669\n",
            "Epoch 5/5, Loss: 0.8201082944869995\n",
            "Validation Loss: 1.4861554028881583, Validation Accuracy: 0.4631\n",
            "Asymmetric Training with noise level: 0.9\n",
            "Epoch 1/5, Loss: 1.2887239456176758\n",
            "Epoch 2/5, Loss: 0.8961564898490906\n",
            "Epoch 3/5, Loss: 0.7993730306625366\n",
            "Epoch 4/5, Loss: 0.737432062625885\n",
            "Epoch 5/5, Loss: 0.8399067521095276\n",
            "Validation Loss: 1.581939093626229, Validation Accuracy: 0.4542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "for key, model_state_info in model_dict.items():\n",
        "\n",
        "    model = BaselineModel()\n",
        "    model_state = model.state_dict()\n",
        "    model_state.update({k: v for k, v in model_state_info['state_dict'].items() if k in model_state})\n",
        "\n",
        "    # load the updated state_dict\n",
        "    model.load_state_dict(model_state)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy for {key}: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nb4dLto0wU3",
        "outputId": "0f9e5e36-12b9-413d-be20-560bfb9a6203"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for noise_level_10_asy: 0.7121\n",
            "Test Accuracy for noise_level_30_asy: 0.6732\n",
            "Test Accuracy for noise_level_50_asy: 0.5824\n",
            "Test Accuracy for noise_level_80_asy: 0.4588\n",
            "Test Accuracy for noise_level_90_asy: 0.4501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "- Used pre-trained Resnet-18 by ImageNet"
      ],
      "metadata": {
        "id": "OKAUBrJa6gKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train & Validation and Testing - symmetric noise label"
      ],
      "metadata": {
        "id": "9SYjLFLs-_4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# noise_levels\n",
        "noise_levels = [0.1, 0.3, 0.5, 0.8, 0.9]\n",
        "num_classes = 10\n",
        "\n",
        "# create a dictionary with keys in the format 'noise_level_{100 * value}'\n",
        "model_dict = {f'noise_level_{int(100 * level)}_sy': None for level in noise_levels}\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# training\n",
        "for epsilon in noise_levels:\n",
        "    num_epochs = 5\n",
        "\n",
        "    model = resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    print(f\"Symmetric Training with noise level: {epsilon}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            # add symmetric noise to labels\n",
        "            labels = apply_label_noise(labels.numpy(), epsilon=epsilon, noise_type='symmetric')\n",
        "            labels = torch.from_numpy(labels)\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    average_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f'Validation Loss: {average_val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "    # save model to dictionary\n",
        "    model_dict[f'noise_level_{int(100 * epsilon)}_sy'] = {\n",
        "        'state_dict': model.state_dict(),\n",
        "        'validation_loss': average_val_loss,\n",
        "        'validation_accuracy': val_accuracy\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCvf4yUQ7CP2",
        "outputId": "561875a0-bfb3-41b0-992d-cccb99e8a76d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symmetric Training with noise level: 0.1\n",
            "Epoch 1/5, Loss: 1.4383738040924072\n",
            "Epoch 2/5, Loss: 0.8490682244300842\n",
            "Epoch 3/5, Loss: 1.07673978805542\n",
            "Epoch 4/5, Loss: 0.8105618953704834\n",
            "Epoch 5/5, Loss: 0.8231915235519409\n",
            "Validation Loss: 0.7404763877012168, Validation Accuracy: 0.7643\n",
            "Symmetric Training with noise level: 0.3\n",
            "Epoch 1/5, Loss: 1.8383228778839111\n",
            "Epoch 2/5, Loss: 1.6291735172271729\n",
            "Epoch 3/5, Loss: 1.667047381401062\n",
            "Epoch 4/5, Loss: 1.4115960597991943\n",
            "Epoch 5/5, Loss: 1.4737496376037598\n",
            "Validation Loss: 0.9268511290762834, Validation Accuracy: 0.7708\n",
            "Symmetric Training with noise level: 0.5\n",
            "Epoch 1/5, Loss: 2.152388334274292\n",
            "Epoch 2/5, Loss: 2.08945894241333\n",
            "Epoch 3/5, Loss: 1.9389090538024902\n",
            "Epoch 4/5, Loss: 2.023054361343384\n",
            "Epoch 5/5, Loss: 2.1566367149353027\n",
            "Validation Loss: 2.9227642565016536, Validation Accuracy: 0.4191\n",
            "Symmetric Training with noise level: 0.8\n",
            "Epoch 1/5, Loss: 2.263587713241577\n",
            "Epoch 2/5, Loss: 2.293323278427124\n",
            "Epoch 3/5, Loss: 2.3045923709869385\n",
            "Epoch 4/5, Loss: 2.3069355487823486\n",
            "Epoch 5/5, Loss: 2.352689027786255\n",
            "Validation Loss: 2.1668198214974375, Validation Accuracy: 0.2845\n",
            "Symmetric Training with noise level: 0.9\n",
            "Epoch 1/5, Loss: 2.3402271270751953\n",
            "Epoch 2/5, Loss: 2.313159227371216\n",
            "Epoch 3/5, Loss: 2.2838549613952637\n",
            "Epoch 4/5, Loss: 2.2856147289276123\n",
            "Epoch 5/5, Loss: 2.3466572761535645\n",
            "Validation Loss: 2.2852638010766095, Validation Accuracy: 0.1754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "for key, model_state_info in model_dict.items():\n",
        "\n",
        "    model = resnet18(pretrained=True)\n",
        "    num_classes = 10\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    model_state = model.state_dict()\n",
        "    model_state.update({k: v for k, v in model_state_info['state_dict'].items() if k in model_state})\n",
        "\n",
        "    # load the updated state_dict\n",
        "    model.load_state_dict(model_state)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy for {key}: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCNZFpue92Dq",
        "outputId": "e409fdaa-cb2f-4adc-dcf7-f6bbd205c15f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for noise_level_10_sy: 0.7643\n",
            "Test Accuracy for noise_level_30_sy: 0.7708\n",
            "Test Accuracy for noise_level_50_sy: 0.4191\n",
            "Test Accuracy for noise_level_80_sy: 0.2845\n",
            "Test Accuracy for noise_level_90_sy: 0.1754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train & Validation and Testing - asymmetric noise label"
      ],
      "metadata": {
        "id": "S_yv1IoT_BSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "0# noise_levels\n",
        "noise_levels = [0.1, 0.3, 0.5, 0.8, 0.9]\n",
        "num_classes = 10\n",
        "\n",
        "# create a dictionary with keys in the format 'noise_level_{100 * value}'\n",
        "model_dict = {f'noise_level_{int(100 * level)}_asy': None for level in noise_levels}\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# training\n",
        "for epsilon in noise_levels:\n",
        "    num_epochs = 5\n",
        "\n",
        "    model = resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    print(f\"Asymmetric Training with noise level: {epsilon}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            # add symmetric noise to labels\n",
        "            labels = apply_label_noise(labels.numpy(), epsilon=epsilon, noise_type='asymmetric')\n",
        "            labels = torch.from_numpy(labels)\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    average_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f'Validation Loss: {average_val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "    # save model to dictionary\n",
        "    model_dict[f'noise_level_{int(100 * epsilon)}_asy'] = {\n",
        "        'state_dict': model.state_dict(),\n",
        "        'validation_loss': average_val_loss,\n",
        "        'validation_accuracy': val_accuracy\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg1OaKbO_Eu8",
        "outputId": "58118088-c6f9-407b-f5f4-a312576988b7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asymmetric Training with noise level: 0.1\n",
            "Epoch 1/5, Loss: 0.7395397424697876\n",
            "Epoch 2/5, Loss: 0.7459056973457336\n",
            "Epoch 3/5, Loss: 0.4033662676811218\n",
            "Epoch 4/5, Loss: 0.7493487000465393\n",
            "Epoch 5/5, Loss: 0.4946557879447937\n",
            "Validation Loss: 0.6455741072915921, Validation Accuracy: 0.7905\n",
            "Asymmetric Training with noise level: 0.3\n",
            "Epoch 1/5, Loss: 0.8711126446723938\n",
            "Epoch 2/5, Loss: 0.8916053771972656\n",
            "Epoch 3/5, Loss: 0.8082765340805054\n",
            "Epoch 4/5, Loss: 0.712039589881897\n",
            "Epoch 5/5, Loss: 0.5307481288909912\n",
            "Validation Loss: 0.7484993021579305, Validation Accuracy: 0.7783\n",
            "Asymmetric Training with noise level: 0.5\n",
            "Epoch 1/5, Loss: 1.0165116786956787\n",
            "Epoch 2/5, Loss: 1.0446757078170776\n",
            "Epoch 3/5, Loss: 0.7705175280570984\n",
            "Epoch 4/5, Loss: 0.7575512528419495\n",
            "Epoch 5/5, Loss: 0.6496548056602478\n",
            "Validation Loss: 0.8887693809855516, Validation Accuracy: 0.5438\n",
            "Asymmetric Training with noise level: 0.8\n",
            "Epoch 1/5, Loss: 0.8771190643310547\n",
            "Epoch 2/5, Loss: 0.528442919254303\n",
            "Epoch 3/5, Loss: 0.5756466388702393\n",
            "Epoch 4/5, Loss: 0.7565357685089111\n",
            "Epoch 5/5, Loss: 0.4672122299671173\n",
            "Validation Loss: 1.2486270711680127, Validation Accuracy: 0.4544\n",
            "Asymmetric Training with noise level: 0.9\n",
            "Epoch 1/5, Loss: 0.768018901348114\n",
            "Epoch 2/5, Loss: 0.6737841367721558\n",
            "Epoch 3/5, Loss: 0.5735059976577759\n",
            "Epoch 4/5, Loss: 0.40505385398864746\n",
            "Epoch 5/5, Loss: 0.5417180061340332\n",
            "Validation Loss: 1.4226876379577977, Validation Accuracy: 0.4746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "for key, model_state_info in model_dict.items():\n",
        "\n",
        "    model = resnet18(pretrained=True)\n",
        "    num_classes = 10\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    model_state = model.state_dict()\n",
        "    model_state.update({k: v for k, v in model_state_info['state_dict'].items() if k in model_state})\n",
        "\n",
        "    # load the updated state_dict\n",
        "    model.load_state_dict(model_state)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy for {key}: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQux4Bsl_PSo",
        "outputId": "6f8634fe-0715-4b6e-9fda-4186bfa9b30b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for noise_level_10_asy: 0.7905\n",
            "Test Accuracy for noise_level_30_asy: 0.7783\n",
            "Test Accuracy for noise_level_50_asy: 0.5438\n",
            "Test Accuracy for noise_level_80_asy: 0.4544\n",
            "Test Accuracy for noise_level_90_asy: 0.4746\n"
          ]
        }
      ]
    }
  ]
}
